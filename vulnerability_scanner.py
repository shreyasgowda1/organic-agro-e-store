import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin

# Function to scan a URL for potential SQL injection vulnerability
def scan_for_sql_injection(url):
    # Send a POST request with a payload to test for SQL injection
    payload = {"id": "' OR 1=1 --"}
    response = requests.post(url, data=payload)
    # Check if the response contains any SQL error messages
    if "SQL syntax" in response.text or "mysql_fetch_array" in response.text:
        return True
    return False

# Function to discover URLs on a webpage
def discover_urls(base_url):
    discovered_urls = set()
    response = requests.get(base_url)
    soup = BeautifulSoup(response.text, "html.parser")
    for link in soup.find_all("a"):
        href = link.get("href")
        if href and href.startswith("http"):
            discovered_urls.add(href)
        else:
            full_url = urljoin(base_url, href)
            discovered_urls.add(full_url)
    return discovered_urls

# Function to scan a website for vulnerabilities
def scan_website(target_url):
    discovered_urls = discover_urls(target_url)
    vulnerabilities = {}
    for url in discovered_urls:
        if scan_for_sql_injection(url):
            vulnerabilities[url] = "SQL Injection Vulnerability Found"
    return vulnerabilities

# Main function
if __name__ == "__main__":
    target_url = input("Enter the target website URL: ")
    vulnerabilities = scan_website(target_url)
    print("Vulnerabilities found:")
    for url, vulnerability in vulnerabilities.items():
        print(url, ":", vulnerability)
